\chapter{Conclusions}\label{chap:6}

\section{Introduction}

This chapter discusses the conclusion of the research project with regard to research questions defined in section \ref{sec:research_questions}. Furthermore, Limitations of the research and further implication of this research is discussed.

\section{Conclusions about research questions (aims/objectives)}

The initial objective of the research was finding a server architecture that would result in the best performance for a given Ballerina program. Initially, three server architectures were implemented in Ballerina run-time by removing, adding, and modifying existing components. Server architectures were chosen based on previous studies \cite{comparing_high_performance_multi_core,comp_ac,flash_server,seda}. The number of thread pools (i.e stages in SEDA) and configuration of thread pools were major points when differentiating the server architectures. Performance of Current Ballerina architecture, Netty OIO, and Removed Ballerina scheduler (specifically scheduler thread pool ) were evaluated against different types of programs. Additionally, two variations of the original Ballerina architecture were implemented by changing the size of the scheduler thread pool. Programs consisted of either CPU-intensive or IO-intensive features. Metrics such as throughput, average latency, standard deviation are evaluated. Experiments in the first phase showed that removing the scheduler thread pool resulted in higher throughput and lower latency for all programs. Furthermore, Netty OIO gave the worst performance for every program. Therefore, it was not possible to identify an architecture that would result in the best performance for a given program among selected architectures. 



Since changing thread pool size affected differently for IO and CPU intensive programs, we tried to answer the second research question which is optimizing the performance of server architecture by tuning the thread pool size. There are several studies \cite{xu2004performance,thread_pool_analysis,math_aproach_thread_pool_tuning,syer2011identifying,linfeng2017design} which try to provide analytical models for thread pool optimization. However, none of them have addressed the thread pool optimization based on different program characteristics. Scheduler thread pool in current the Ballerina architecture is selected over removed scheduler architecture in order to tune because of stability issues referred in section when the load to the web server (no. of concurrent users) is increased. New programs were added for testing which has different IO characteristics (Database calls, HTTP calls, gRPC calls). Experiments were designed to measure the impact of thread pool size for different IO features in programs. We were able to determine the impact of thread pool size for different programs which consisted of different IO features. We were able to find thread pool size which gives minimum average latency for each program.


The final objective was deriving a model to predict optimal thread pool size based on a given set of programming features. A machine learning model was trained in order to answer the last research question. The model takes input as features in the given ballerina program (i.e Number of database calls, HTTP calls, gRPC calls, loops) and estimates optimal thread pool size as output. Among several machine learning models, the Decision Tree Regression model was chosen based on evaluation metrics. Hence, we were able to devise a model that estimates the thread pool size for a given Ballerina program.

Finally, the performance of default Ballerina thread pool size and thread pool size predicted by the machine learning model is evaluated for two programs. The size predicted from the machine learning model performed well over the default Ballerina thread pool size for programs. 


\section{Conclusions about research problem}

In this research, we are able to propose a model to estimate optimal thread pool size for a given Ballerina program. Ballerina's native representation of remote IO calls a.k.a connector calls and other web service oriented features supported to extract these features directly from source code by parsing AST tree. The combination of all modules makes it easier to decide the optimal thread pool size for the Ballerina scheduler prior to the execution of the program. This process can be integrated into the compilation process of the Ballerina program resulting in automatic thread pool size configuration in compiled code. The result of this study can be used as proof of concept for performance estimation based on programming features.

Furthermore, heuristic rules such as deciding the number of thread pool size as twice the number of CPU \cite{thread_pool_analysis} is not resulting in optimal performance has been proven when analyzing the results of the first phase. In figures \ref{phase-1-database-all-architectures},\ref{phase-1-prime-small-all-architectures},\ref{phase-1-prime-medium-all-architectures},\ref{phase-1-prime-large-all-architectures},\ref{phase-1-file-read-all-architectures} , (Note that \textit{scheduler x2} represent 4 times the number of CPUs and \textit{scheduler x4} results 8 times the number of CPUs ) we can see that performance is better when the number of threads are 4 times the number of CPUs than the current ballerina architecture where default thread pool size is 2 times the number of CPUs for all tested program types. 


\section{Limitations}

There are several limitations that occurred while progressing the research. In the first phase of the research, we analyzed both CPU intensive and IO intensive applications. However, when building the machine learning model it was difficult to extract CPU intensive features directly from the source code. Thus, only IO characteristics were considered which were able to parse from source code. As an example, we can model the CPU intensive behaviors as the number of variable assignments, comparisons, and arithmetic operations then it is possible to extract this information from source code. But when 3rd party library function calls are happening, it is not able to derive this information directly from the source code. This requires analysis of compiled byte code than source code. Thus, this study did not explore that level.

Furthermore, the results of the experiment can be subject to the environment of the machine where the server is deployed. The effect of the amount of RAM number of the CPU is not analyzed in this research.

Also, performance results can be subject to run time variables as well. This study only provides static analysis. As an example, the number of times that particular loop is executing can be depended on a variable. Some paths of the program may never get executed. Thus, for a given program features that are affected at run time may differ from the static information.



\section{Implications for further research}

For future studies, this proof of concept can be made as to the ground with a combination of the above limitations. We are able to prove that performance of web servers can be modeled based on program features. In this research, we only considered the Ballerina language. The same set of experiments can be conducted for other frameworks and languages. If we can extract information from compiled code (byte-code in java) we can integrate the total number of expressions, assignments, comparisons, loops and if-clauses including 3rd party libraries as well. Then we can build an accurate model which includes both IO and CPU intensive features. Moreover, we can get relation among the Number of CPU, Amount of RAM, etc by running this model in multiple environments.     
